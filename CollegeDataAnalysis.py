# -*- coding: utf-8 -*-
"""Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1j_lZYdelAFK_LTnEeLhngnbyy3ywUK0C
"""

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib.backends.backend_pdf import PdfPages
import warnings
warnings.filterwarnings('ignore')

from sklearn.model_selection import StratifiedShuffleSplit, train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import recall_score, accuracy_score, precision_score, f1_score, roc_curve, auc, classification_report
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, RandomForestRegressor
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression, LinearRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from xgboost import XGBClassifier
from catboost import CatBoostClassifier

def analyze_college_data(data_path, pdf_pages):
    data = pd.read_csv(data_path)

    # Statistical summary
    summary = data.describe()
    fig, ax = plt.subplots(figsize=(12, 8))
    ax.axis('off')
    ax.table(cellText=np.round(summary.values, 2), colLabels=summary.columns, rowLabels=summary.index, loc='center')
    ax.set_title("Statistical Summary", fontweight="bold")
    plt.tight_layout()
    pdf_pages.savefig()
    plt.close()
    
    # Graduation rate pie chart
    plt.figure(figsize=(8,8))
    labels = ['<50%', '50-60%', '60-70%', '70-80%', '80-90%', '90-100%']
    bins = [0, 50, 60, 70, 80, 90, 100]
    data['Grad.Rate_Bin'] = pd.cut(data['Grad.Rate'], bins=bins, labels=labels)
    sizes = data['Grad.Rate_Bin'].value_counts().sort_index()
    plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=140, colors=sns.color_palette('pastel'))
    plt.title('Graduation Rate Distribution')
    pdf_pages.savefig()
    plt.close()
    
    # Public vs Private countplot
    plt.figure(figsize=(10,6))
    sns.countplot(x='Private', data=data, palette='coolwarm')
    plt.title('Distribution of Private and Public Universities')
    pdf_pages.savefig()
    plt.close()
    
    # Student-Faculty Ratio
    plt.figure(figsize=(10,6))
    sns.barplot(x='Private', y='S.F.Ratio', data=data, palette='viridis')
    plt.title('Student-Faculty Ratio in Private vs Public Universities')
    pdf_pages.savefig()
    plt.close()
    
    # Correlation heatmap
    plt.figure(figsize=(12,10))
    sns.heatmap(data.corr(), annot=True, cmap='coolwarm', fmt=".2f")
    plt.title('Correlation Heatmap')
    pdf_pages.savefig()
    plt.close()
    
    # Out-of-State Tuition vs Acceptance Rate
    plt.figure(figsize=(10,6))
    sns.scatterplot(x='Outstate', y='Accept', hue='Private', data=data, palette='Set1', s=100, alpha=0.7)
    plt.title('Out-of-State Tuition vs Acceptance Rate')
    pdf_pages.savefig()
    plt.close()
    
    # KDE plots for Outstate Tuition & Personal Spending
    plt.figure(figsize=(10,6))
    sns.kdeplot(data['Outstate'], shade=True, label='Outstate Tuition')
    sns.kdeplot(data['Personal'], shade=True, label='Personal Spending')
    plt.title('Tuition and Personal Spending Distribution')
    plt.legend()
    pdf_pages.savefig()
    plt.close()
    
    # Boxplot for Outstate Tuition by University Type
    plt.figure(figsize=(10,6))
    sns.boxplot(x='Private', y='Outstate', data=data, palette='Set2')
    plt.title('Outstate Tuition by University Type')
    pdf_pages.savefig()
    plt.close()

def classify_college_data(data_path, pdf_pages):
    data = pd.read_csv(data_path)
    data['Private'] = data['Private'].map({'Yes': 1, 'No': 0})
    data.dropna(inplace=True)
    
    X = data.iloc[:, 2:]
    y = data['Private'].values

    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)
    for train_idx, test_idx in sss.split(X_scaled, y):
        X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]
        y_train, y_test = y[train_idx], y[test_idx]
        break
    
    classifiers = [
        ("Random Forest", RandomForestClassifier(random_state=42)),
        ("SVM", SVC(probability=True, random_state=42)),
        ("Logistic Regression", LogisticRegression(random_state=42)),
        ("KNN", KNeighborsClassifier(n_neighbors=5)),
        ("Naive Bayes", GaussianNB()),
        ("Decision Tree", DecisionTreeClassifier(random_state=42)),
        ("AdaBoost", AdaBoostClassifier(random_state=42)),
        ("Gradient Boosting", GradientBoostingClassifier(random_state=42)),
        ("XGBoost", XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)),
        ("CatBoost", CatBoostClassifier(logging_level='Silent', random_state=42))
    ]
    
    results = {}
    for name, clf in classifiers:
        clf.fit(X_train, y_train)
        y_pred = clf.predict(X_test)
        results[name] = {
            "Recall": recall_score(y_test, y_pred),
            "Accuracy": accuracy_score(y_test, y_pred),
            "Precision": precision_score(y_test, y_pred),
            "F1": f1_score(y_test, y_pred, average='macro')
        }
        
        if hasattr(clf, "predict_proba"):
            y_proba = clf.predict_proba(X_test)[:, 1]
        elif hasattr(clf, "decision_function"):
            y_proba = clf.decision_function(X_test)
        else:
            y_proba = None

        if y_proba is not None:
            fpr, tpr, _ = roc_curve(y_test, y_proba)
            roc_auc = auc(fpr, tpr)
            plt.figure(figsize=(8,6))
            plt.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc:.2f})')
            plt.plot([0, 1], [0, 1], 'k--')
            plt.xlabel('False Positive Rate')
            plt.ylabel('True Positive Rate')
            plt.title(f'ROC Curve - {name}')
            plt.legend(loc='lower right')
            pdf_pages.savefig()
            plt.close()
    
    results_df = pd.DataFrame(results).T
    results_df.plot(kind='bar', figsize=(12,8))
    plt.title("Model Comparison")
    plt.ylabel("Score")
    plt.xticks(rotation=45)
    plt.tight_layout()
    pdf_pages.savefig()
    plt.close()
    
    report = classification_report(y_test, classifiers[0][1].predict(X_test))
    with open("classification_report.txt", "w") as f:
        f.write(report)

def prescriptive_analytics(data_path, pdf_pages):
    data = pd.read_csv(data_path)
    data.dropna(inplace=True)
    data['Private'] = data['Private'].map({'Yes': 1, 'No': 0})
    
    features = data.drop(['Grad.Rate'] + (['Unnamed: 0'] if 'Unnamed: 0' in data.columns else []), axis=1)
    target = data['Grad.Rate']
    
    # Linear Regression
    lin_reg = LinearRegression()
    lin_reg.fit(features, target)
    coef = pd.DataFrame(lin_reg.coef_, features.columns, columns=['Coefficient'])
    plt.figure(figsize=(12,6))
    coef['Coefficient'].abs().sort_values(ascending=False).plot(kind='bar')
    plt.title("Linear Regression Coefficients")
    plt.tight_layout()
    pdf_pages.savefig()
    plt.close()
    
    # Random Forest Regressor
    rf_reg = RandomForestRegressor(random_state=42)
    rf_reg.fit(features, target)
    imp = pd.Series(rf_reg.feature_importances_, index=features.columns)
    plt.figure(figsize=(12,6))
    imp.sort_values(ascending=False).plot(kind='bar')
    plt.title("Random Forest Feature Importances")
    plt.tight_layout()
    pdf_pages.savefig()
    plt.close()

def main():
    data_path = "College_Data.csv"
    output_pdf = "output_report.pdf"
    
    with PdfPages(output_pdf) as pdf_pages:
        analyze_college_data(data_path, pdf_pages)
        classify_college_data(data_path, pdf_pages)
        prescriptive_analytics(data_path, pdf_pages)
    
    print(f"Output saved to '{output_pdf}'.")

if __name__ == "__main__":
    main()

